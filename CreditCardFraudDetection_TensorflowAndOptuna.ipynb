{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7a41af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5c44cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of True positives in the dataset: 2.66 % \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18516, 31)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data was visualised in 'CreditCardFraudPrediction_DataVisualization_and_FeatureSelection' notebook\n",
    "#Selecting all positives and some 15000 negatives(shuffled)\n",
    "#Number of required false negatives can be tuned as well.\n",
    "\n",
    "ccdb = pd.read_csv('creditcarddb/creditcard.csv')\n",
    "db1 = ccdb.loc[(np.abs(ccdb.iloc[:,12].mean() - ccdb.iloc[:,12]))/ccdb.iloc[:,12].std() > 3]\n",
    "db2 = ccdb.loc[((np.abs(ccdb.iloc[:,12].mean() - ccdb.iloc[:,12]))/ccdb.iloc[:,12].std() < 3) & (ccdb['Class'] == 1) ]\n",
    "db3 = ccdb.loc[((np.abs(ccdb.iloc[:,12].mean() - ccdb.iloc[:,12]))/ccdb.iloc[:,12].std() < 3) & (ccdb['Class'] == 0)]\n",
    "db3 = db3.sample(frac = 1)\n",
    "db3 =  db3.iloc[:15000,:]\n",
    "ccdb = pd.concat([db1, db2, db3], ignore_index=True)\n",
    "ccdb = ccdb.sample(frac = 1)\n",
    "print(\"Percentage of True positives in the dataset: \"'{s}'\" % \".format(s = round((ccdb['Class'].sum()/ccdb['Class'].count()) * 100,2)))\n",
    "ccdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "53da489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to skewness of data, f1 score will be a better measure than accuracy\n",
    "\n",
    "def custom_f1(y_true, y_pred):\n",
    "    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c17aa06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is valid only if we use random state. train and test data must come from the same distribution.\n",
    "def split_scale_data(df_x,df_y,test_size=0.2,phase='train'):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state= 5) \n",
    "    Scalar = StandardScaler()\n",
    "    Scalar.fit(x_train)\n",
    "    x_train = Scalar.transform(x_train)\n",
    "    x_test = Scalar.transform(x_test)\n",
    "    \n",
    "    if phase == 'train':\n",
    "        x = x_train\n",
    "        y = y_train\n",
    "        \n",
    "    elif phase == 'test':\n",
    "        x = x_test\n",
    "        y = y_test\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a416ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optuna will try to tune this using different values for H params\n",
    "def define_model(trial):\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\",1,3)\n",
    "    layers = []\n",
    "    activation_list=[\"relu\",\"sigmoid\"]\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        #We'll automate hyperparm tuning using a bayesien method\n",
    "        num_nodes = int(trial.suggest_loguniform('n_units_{}'.format(i),4,128))\n",
    "        activation = trial.suggest_categorical(\"activation_{}\".format(i),activation_list)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate_{}'.format(i),0.0,0.95)\n",
    "        lambda_reg = trial.suggest_float('lambda_reg_{}'.format(i),1e-10, 1e-3, log=True)\n",
    "        \n",
    "        #basic NN model \n",
    "        model.add(tf.keras.layers.Dense(num_nodes,input_shape = (30,),activation=activation,kernel_regularizer=tf.keras.regularizers.l2(lambda_reg)))\n",
    "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    #adding the output layer\n",
    "    model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c68e1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We try to find the best Optimizer as well\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    # We optimize the choice of optimizers as well as their parameters.\n",
    "    kwargs = {}\n",
    "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
    "    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
    "    if optimizer_selected == \"RMSprop\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"rmsprop_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        kwargs[\"decay\"] = trial.suggest_float(\"rmsprop_decay\", 0.85, 0.99)\n",
    "        kwargs[\"momentum\"] = trial.suggest_float(\"rmsprop_momentum\", 1e-5, 1e-1, log=True)\n",
    "    elif optimizer_selected == \"Adam\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"adam_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    elif optimizer_selected == \"SGD\":\n",
    "        kwargs[\"learning_rate\"] = trial.suggest_float(\"sgd_opt_learning_rate\", 1e-5, 1e-1, log=True)\n",
    "        kwargs[\"momentum\"] = trial.suggest_float(\"sgd_opt_momentum\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ab6b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 725\n",
    "\n",
    "#Will explore Pruning more in the next project\n",
    "PRUNING_INTERVAL_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06199ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used a custom metric to be as the objective, my goal was to tune Hparams to fix bias and variance at the same time\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    x_train,y_train = split_scale_data(ccdb.iloc[:,:-1],ccdb.iloc[:,-1])\n",
    "    \n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2, log = True)\n",
    "    \n",
    "    batch_size = trial.suggest_int(\"batch_size\",100,10000)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    # Build model and compile.\n",
    "    model = define_model(trial)\n",
    "    model.compile(optimizer=optimizer,loss=bce,metrics=custom_f1)\n",
    "    history = model.fit(x_train,y_train,batch_size=batch_size,validation_split=0.2,epochs=EPOCHS)\n",
    "    \n",
    "    f1 = history.history['val_custom_f1'][-1]\n",
    "    loss = history.history['loss'][-1]\n",
    "    val_loss =  history.history['val_loss'][-1]\n",
    "\n",
    "    optuna_pruning_hook = optuna.integration.TensorFlowPruningHook(\n",
    "        trial=trial,\n",
    "        estimator=model,\n",
    "        metric=(abs(loss - val_loss)*40) - f1,\n",
    "        run_every_steps=PRUNING_INTERVAL_STEPS,\n",
    "    )\n",
    "    \n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    #clearing the model after every test\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    # :)\n",
    "    return (abs(loss - val_loss)*40) - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46a3bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-11 02:18:03,350]\u001b[0m A new study created in memory with name: no-name-cf630f3e-ba27-474b-ab90-91879a7818f7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/725\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.9269 - custom_f1: 0.0460 - val_loss: 0.5950 - val_custom_f1: 0.0182\n",
      "Epoch 2/725\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8813 - custom_f1: 0.0456 - val_loss: 0.5616 - val_custom_f1: 0.0118\n",
      "Epoch 3/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.8360 - custom_f1: 0.0474 - val_loss: 0.5312 - val_custom_f1: 0.0000e+00\n",
      "Epoch 4/725\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.7946 - custom_f1: 0.0442 - val_loss: 0.5035 - val_custom_f1: 0.0000e+00\n",
      "Epoch 5/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7582 - custom_f1: 0.0464 - val_loss: 0.4780 - val_custom_f1: 0.0000e+00\n",
      "Epoch 6/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.7211 - custom_f1: 0.0498 - val_loss: 0.4551 - val_custom_f1: 0.0000e+00\n",
      "Epoch 7/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6937 - custom_f1: 0.0439 - val_loss: 0.4347 - val_custom_f1: 0.0000e+00\n",
      "Epoch 8/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6628 - custom_f1: 0.0481 - val_loss: 0.4161 - val_custom_f1: 0.0000e+00\n",
      "Epoch 9/725\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6423 - custom_f1: 0.0441 - val_loss: 0.3987 - val_custom_f1: 0.0000e+00\n",
      "Epoch 10/725\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6186 - custom_f1: 0.0449 - val_loss: 0.3827 - val_custom_f1: 0.0000e+00\n",
      "Epoch 11/725\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5920 - custom_f1: 0.0517 - val_loss: 0.3682 - val_custom_f1: 0.0000e+00\n",
      "Epoch 12/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5679 - custom_f1: 0.0553 - val_loss: 0.3549 - val_custom_f1: 0.0000e+00\n",
      "Epoch 13/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5492 - custom_f1: 0.0567 - val_loss: 0.3424 - val_custom_f1: 0.0000e+00\n",
      "Epoch 14/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5298 - custom_f1: 0.0516 - val_loss: 0.3307 - val_custom_f1: 0.0000e+00\n",
      "Epoch 15/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5146 - custom_f1: 0.0588 - val_loss: 0.3199 - val_custom_f1: 0.0000e+00\n",
      "Epoch 16/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5003 - custom_f1: 0.0507 - val_loss: 0.3099 - val_custom_f1: 0.0000e+00\n",
      "Epoch 17/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4816 - custom_f1: 0.0561 - val_loss: 0.3006 - val_custom_f1: 0.0000e+00\n",
      "Epoch 18/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4675 - custom_f1: 0.0588 - val_loss: 0.2917 - val_custom_f1: 0.0000e+00\n",
      "Epoch 19/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4563 - custom_f1: 0.0583 - val_loss: 0.2836 - val_custom_f1: 0.0000e+00\n",
      "Epoch 20/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4442 - custom_f1: 0.0535 - val_loss: 0.2762 - val_custom_f1: 0.0000e+00\n",
      "Epoch 21/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4312 - custom_f1: 0.0441 - val_loss: 0.2692 - val_custom_f1: 0.0000e+00\n",
      "Epoch 22/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4260 - custom_f1: 0.0464 - val_loss: 0.2626 - val_custom_f1: 0.0000e+00\n",
      "Epoch 23/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4076 - custom_f1: 0.0547 - val_loss: 0.2563 - val_custom_f1: 0.0000e+00\n",
      "Epoch 24/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4021 - custom_f1: 0.0559 - val_loss: 0.2504 - val_custom_f1: 0.0000e+00\n",
      "Epoch 25/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3882 - custom_f1: 0.0589 - val_loss: 0.2449 - val_custom_f1: 0.0000e+00\n",
      "Epoch 26/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3828 - custom_f1: 0.0640 - val_loss: 0.2396 - val_custom_f1: 0.0000e+00\n",
      "Epoch 27/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3704 - custom_f1: 0.0569 - val_loss: 0.2346 - val_custom_f1: 0.0000e+00\n",
      "Epoch 28/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3656 - custom_f1: 0.0606 - val_loss: 0.2298 - val_custom_f1: 0.0000e+00\n",
      "Epoch 29/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3566 - custom_f1: 0.0508 - val_loss: 0.2254 - val_custom_f1: 0.0000e+00\n",
      "Epoch 30/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3506 - custom_f1: 0.0416 - val_loss: 0.2212 - val_custom_f1: 0.0000e+00\n",
      "Epoch 31/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3426 - custom_f1: 0.0694 - val_loss: 0.2172 - val_custom_f1: 0.0000e+00\n",
      "Epoch 32/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3358 - custom_f1: 0.0524 - val_loss: 0.2134 - val_custom_f1: 0.0000e+00\n",
      "Epoch 33/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3269 - custom_f1: 0.0622 - val_loss: 0.2098 - val_custom_f1: 0.0000e+00\n",
      "Epoch 34/725\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3235 - custom_f1: 0.0656 - val_loss: 0.2064 - val_custom_f1: 0.0000e+00\n",
      "Epoch 35/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3155 - custom_f1: 0.0670 - val_loss: 0.2032 - val_custom_f1: 0.0000e+00\n",
      "Epoch 36/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3118 - custom_f1: 0.0678 - val_loss: 0.2001 - val_custom_f1: 0.0000e+00\n",
      "Epoch 37/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3061 - custom_f1: 0.0656 - val_loss: 0.1972 - val_custom_f1: 0.0000e+00\n",
      "Epoch 38/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2976 - custom_f1: 0.0876 - val_loss: 0.1943 - val_custom_f1: 0.0000e+00\n",
      "Epoch 39/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2982 - custom_f1: 0.0642 - val_loss: 0.1916 - val_custom_f1: 0.0000e+00\n",
      "Epoch 40/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2917 - custom_f1: 0.0748 - val_loss: 0.1890 - val_custom_f1: 0.0000e+00\n",
      "Epoch 41/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2902 - custom_f1: 0.0722 - val_loss: 0.1866 - val_custom_f1: 0.0000e+00\n",
      "Epoch 42/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2886 - custom_f1: 0.0667 - val_loss: 0.1842 - val_custom_f1: 0.0000e+00\n",
      "Epoch 43/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2833 - custom_f1: 0.0684 - val_loss: 0.1820 - val_custom_f1: 0.0000e+00\n",
      "Epoch 44/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2739 - custom_f1: 0.0677 - val_loss: 0.1798 - val_custom_f1: 0.0000e+00\n",
      "Epoch 45/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2706 - custom_f1: 0.0861 - val_loss: 0.1778 - val_custom_f1: 0.0000e+00\n",
      "Epoch 46/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2662 - custom_f1: 0.0791 - val_loss: 0.1758 - val_custom_f1: 0.0000e+00\n",
      "Epoch 47/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2664 - custom_f1: 0.0590 - val_loss: 0.1739 - val_custom_f1: 0.0000e+00\n",
      "Epoch 48/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2624 - custom_f1: 0.0823 - val_loss: 0.1721 - val_custom_f1: 0.0000e+00\n",
      "Epoch 49/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2556 - custom_f1: 0.0897 - val_loss: 0.1704 - val_custom_f1: 0.0000e+00\n",
      "Epoch 50/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2573 - custom_f1: 0.0629 - val_loss: 0.1687 - val_custom_f1: 0.0000e+00\n",
      "Epoch 51/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2496 - custom_f1: 0.0753 - val_loss: 0.1671 - val_custom_f1: 0.0000e+00\n",
      "Epoch 52/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2443 - custom_f1: 0.0990 - val_loss: 0.1655 - val_custom_f1: 0.0000e+00\n",
      "Epoch 53/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2475 - custom_f1: 0.0978 - val_loss: 0.1641 - val_custom_f1: 0.0000e+00\n",
      "Epoch 54/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2421 - custom_f1: 0.0536 - val_loss: 0.1626 - val_custom_f1: 0.0000e+00\n",
      "Epoch 55/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2415 - custom_f1: 0.0925 - val_loss: 0.1612 - val_custom_f1: 0.0000e+00\n",
      "Epoch 56/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2398 - custom_f1: 0.0802 - val_loss: 0.1599 - val_custom_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2325 - custom_f1: 0.0864 - val_loss: 0.1586 - val_custom_f1: 0.0000e+00\n",
      "Epoch 58/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2311 - custom_f1: 0.1280 - val_loss: 0.1573 - val_custom_f1: 0.0000e+00\n",
      "Epoch 59/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2269 - custom_f1: 0.1003 - val_loss: 0.1561 - val_custom_f1: 0.0000e+00\n",
      "Epoch 60/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2261 - custom_f1: 0.0929 - val_loss: 0.1549 - val_custom_f1: 0.0000e+00\n",
      "Epoch 61/725\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2275 - custom_f1: 0.0667 - val_loss: 0.1538 - val_custom_f1: 0.0000e+00\n",
      "Epoch 62/725\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2231 - custom_f1: 0.0972 - val_loss: 0.1527 - val_custom_f1: 0.0000e+00\n",
      "Epoch 63/725\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1964/2137157349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1964/2027551992.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_custom_f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#This works amazingly well!\n",
    "''''[I 2021-10-10 23:09:40,228] Trial 84 finished with value: -0.855547696352005 and parameters: \n",
    "{'learning_rate': 0.0021393523564096763, 'batch_size': 5326, 'optimizer': 'Adam', 'adam_learning_rate': 0.056347979238179594,\n",
    "'n_layers': 2, 'n_units_0': 32.792881084659115, 'activation_0': 'relu', 'dropout_rate_0': 0.7268295637416722,\n",
    "'lambda_reg_0': 5.8003894835056825e-06, 'n_units_1': 35.78671685284347, 'activation_1': 'sigmoid',\n",
    "'dropout_rate_1': 0.2226073287239269, 'lambda_reg_1': 1.018643186769918e-09}. \n",
    "Best is trial 84 with value: -0.855547696352005.'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=200)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I used a custom metric to be as the objective, my goal was to tune Hparams to fix bias and variance at the same time\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    x_train,y_train = split_scale_data(ccdb.iloc[:,:-1],ccdb.iloc[:,-1])\n",
    "    \n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-2, log = True)\n",
    "    \n",
    "    batch_size = trial.suggest_int(\"batch_size\",100,10000)\n",
    "    optimizer = create_optimizer(trial)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    # Build model and compile.\n",
    "    model = define_model(trial)\n",
    "    model.compile(optimizer=optimizer,loss=bce,metrics=custom_f1)\n",
    "    history = model.fit(x_train,y_train,batch_size=batch_size,validation_split=0.2,epochs=EPOCHS)\n",
    "    \n",
    "    f1 = history.history['val_custom_f1'][-1]\n",
    "    loss = history.history['loss'][-1]\n",
    "    val_loss =  history.history['val_loss'][-1]\n",
    "\n",
    "    optuna_pruning_hook = optuna.integration.TensorFlowPruningHook(\n",
    "        trial=trial,\n",
    "        estimator=model,\n",
    "        metric=(abs(loss - val_loss)*40) - f1,\n",
    "        run_every_steps=PRUNING_INTERVAL_STEPS,\n",
    "    )\n",
    "    \n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    #clearing the model after every test\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    \n",
    "    # :)\n",
    "    return (abs(loss - val_loss)*40) - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47584349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A better way would be to just load the best model instead of manually creating another model\n",
    "\n",
    "def final_model(input_shape,lr):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(32,input_shape = (input_shape,),activation='relu',kernel_regularizer=tf.keras.regularizers.l2(5.8e-06)))\n",
    "    model.add(tf.keras.layers.Dropout(0.72))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(36,activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l2(1.09e-09)))\n",
    "    model.add(tf.keras.layers.Dropout(0.22))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(optimizer=optimizer,loss=bce,metrics=custom_f1)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b036502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/725\n",
      "3/3 [==============================] - 1s 97ms/step - loss: 0.7648 - custom_f1: 0.0810 - val_loss: 0.4073 - val_custom_f1: 0.2316\n",
      "Epoch 2/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3331 - custom_f1: 0.2852 - val_loss: 0.1086 - val_custom_f1: 0.0000e+00\n",
      "Epoch 3/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1156 - custom_f1: 0.6093 - val_loss: 0.0729 - val_custom_f1: 0.0000e+00\n",
      "Epoch 4/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0602 - custom_f1: 0.6698 - val_loss: 0.1204 - val_custom_f1: 0.0000e+00\n",
      "Epoch 5/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0637 - custom_f1: 0.6539 - val_loss: 0.1593 - val_custom_f1: 0.0000e+00\n",
      "Epoch 6/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0678 - custom_f1: 0.6638 - val_loss: 0.1806 - val_custom_f1: 0.0000e+00\n",
      "Epoch 7/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0644 - custom_f1: 0.7372 - val_loss: 0.1905 - val_custom_f1: 0.0000e+00\n",
      "Epoch 8/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0611 - custom_f1: 0.6595 - val_loss: 0.1925 - val_custom_f1: 0.0000e+00\n",
      "Epoch 9/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0570 - custom_f1: 0.6328 - val_loss: 0.1841 - val_custom_f1: 0.0000e+00\n",
      "Epoch 10/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0610 - custom_f1: 0.6711 - val_loss: 0.1763 - val_custom_f1: 0.0000e+00\n",
      "Epoch 11/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0480 - custom_f1: 0.6692 - val_loss: 0.1636 - val_custom_f1: 0.0000e+00\n",
      "Epoch 12/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0472 - custom_f1: 0.7712 - val_loss: 0.1539 - val_custom_f1: 0.0000e+00\n",
      "Epoch 13/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0437 - custom_f1: 0.7868 - val_loss: 0.1481 - val_custom_f1: 0.0000e+00\n",
      "Epoch 14/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0421 - custom_f1: 0.7436 - val_loss: 0.1421 - val_custom_f1: 0.0000e+00\n",
      "Epoch 15/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0424 - custom_f1: 0.7938 - val_loss: 0.1369 - val_custom_f1: 0.0000e+00\n",
      "Epoch 16/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0438 - custom_f1: 0.7766 - val_loss: 0.1344 - val_custom_f1: 0.0000e+00\n",
      "Epoch 17/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0405 - custom_f1: 0.7827 - val_loss: 0.1325 - val_custom_f1: 0.0000e+00\n",
      "Epoch 18/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0416 - custom_f1: 0.7978 - val_loss: 0.1287 - val_custom_f1: 0.0000e+00\n",
      "Epoch 19/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0408 - custom_f1: 0.7550 - val_loss: 0.1265 - val_custom_f1: 0.0000e+00\n",
      "Epoch 20/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0434 - custom_f1: 0.7470 - val_loss: 0.1254 - val_custom_f1: 0.0000e+00\n",
      "Epoch 21/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0423 - custom_f1: 0.7555 - val_loss: 0.1206 - val_custom_f1: 0.0000e+00\n",
      "Epoch 22/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0402 - custom_f1: 0.7780 - val_loss: 0.1184 - val_custom_f1: 0.0000e+00\n",
      "Epoch 23/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0411 - custom_f1: 0.7885 - val_loss: 0.1193 - val_custom_f1: 0.0000e+00\n",
      "Epoch 24/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0407 - custom_f1: 0.7514 - val_loss: 0.1180 - val_custom_f1: 0.0000e+00\n",
      "Epoch 25/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0398 - custom_f1: 0.7717 - val_loss: 0.1153 - val_custom_f1: 0.0000e+00\n",
      "Epoch 26/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0393 - custom_f1: 0.7792 - val_loss: 0.1119 - val_custom_f1: 0.0000e+00\n",
      "Epoch 27/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0418 - custom_f1: 0.8107 - val_loss: 0.1105 - val_custom_f1: 0.0000e+00\n",
      "Epoch 28/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0381 - custom_f1: 0.8008 - val_loss: 0.1081 - val_custom_f1: 0.0000e+00\n",
      "Epoch 29/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0392 - custom_f1: 0.7922 - val_loss: 0.1051 - val_custom_f1: 0.0000e+00\n",
      "Epoch 30/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0404 - custom_f1: 0.8061 - val_loss: 0.1028 - val_custom_f1: 0.0000e+00\n",
      "Epoch 31/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - custom_f1: 0.8070 - val_loss: 0.1068 - val_custom_f1: 0.0000e+00\n",
      "Epoch 32/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0375 - custom_f1: 0.8127 - val_loss: 0.1101 - val_custom_f1: 0.0000e+00\n",
      "Epoch 33/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.7804 - val_loss: 0.1092 - val_custom_f1: 0.0000e+00\n",
      "Epoch 34/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.7878 - val_loss: 0.1102 - val_custom_f1: 0.0000e+00\n",
      "Epoch 35/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0381 - custom_f1: 0.7699 - val_loss: 0.1095 - val_custom_f1: 0.0000e+00\n",
      "Epoch 36/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8117 - val_loss: 0.1059 - val_custom_f1: 0.0000e+00\n",
      "Epoch 37/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0388 - custom_f1: 0.8152 - val_loss: 0.1007 - val_custom_f1: 0.0000e+00\n",
      "Epoch 38/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8036 - val_loss: 0.0984 - val_custom_f1: 0.0000e+00\n",
      "Epoch 39/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7937 - val_loss: 0.0998 - val_custom_f1: 0.0000e+00\n",
      "Epoch 40/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0375 - custom_f1: 0.7951 - val_loss: 0.0976 - val_custom_f1: 0.0000e+00\n",
      "Epoch 41/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8053 - val_loss: 0.0969 - val_custom_f1: 0.0000e+00\n",
      "Epoch 42/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0383 - custom_f1: 0.7843 - val_loss: 0.0962 - val_custom_f1: 0.0000e+00\n",
      "Epoch 43/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8065 - val_loss: 0.0885 - val_custom_f1: 0.0000e+00\n",
      "Epoch 44/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0387 - custom_f1: 0.8069 - val_loss: 0.0861 - val_custom_f1: 0.0000e+00\n",
      "Epoch 45/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8189 - val_loss: 0.0896 - val_custom_f1: 0.0000e+00\n",
      "Epoch 46/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.7675 - val_loss: 0.0904 - val_custom_f1: 0.0000e+00\n",
      "Epoch 47/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0381 - custom_f1: 0.7923 - val_loss: 0.0891 - val_custom_f1: 0.0000e+00\n",
      "Epoch 48/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8084 - val_loss: 0.0867 - val_custom_f1: 0.0000e+00\n",
      "Epoch 49/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8259 - val_loss: 0.0872 - val_custom_f1: 0.0000e+00\n",
      "Epoch 50/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.8077 - val_loss: 0.0848 - val_custom_f1: 0.0000e+00\n",
      "Epoch 51/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.7974 - val_loss: 0.0783 - val_custom_f1: 0.0000e+00\n",
      "Epoch 52/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8045 - val_loss: 0.0753 - val_custom_f1: 0.0000e+00\n",
      "Epoch 53/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0384 - custom_f1: 0.7866 - val_loss: 0.0731 - val_custom_f1: 0.0000e+00\n",
      "Epoch 54/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8232 - val_loss: 0.0757 - val_custom_f1: 0.0000e+00\n",
      "Epoch 55/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0396 - custom_f1: 0.7750 - val_loss: 0.0783 - val_custom_f1: 0.0000e+00\n",
      "Epoch 56/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.7936 - val_loss: 0.0758 - val_custom_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0390 - custom_f1: 0.8008 - val_loss: 0.0691 - val_custom_f1: 0.0000e+00\n",
      "Epoch 58/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8058 - val_loss: 0.0667 - val_custom_f1: 0.0000e+00\n",
      "Epoch 59/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8163 - val_loss: 0.0705 - val_custom_f1: 0.0000e+00\n",
      "Epoch 60/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.7876 - val_loss: 0.0747 - val_custom_f1: 0.0000e+00\n",
      "Epoch 61/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8006 - val_loss: 0.0690 - val_custom_f1: 0.0000e+00\n",
      "Epoch 62/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0368 - custom_f1: 0.8279 - val_loss: 0.0632 - val_custom_f1: 0.0000e+00\n",
      "Epoch 63/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0374 - custom_f1: 0.7977 - val_loss: 0.0622 - val_custom_f1: 0.0000e+00\n",
      "Epoch 64/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8034 - val_loss: 0.0622 - val_custom_f1: 0.0000e+00\n",
      "Epoch 65/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7811 - val_loss: 0.0625 - val_custom_f1: 0.0000e+00\n",
      "Epoch 66/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8078 - val_loss: 0.0610 - val_custom_f1: 0.0000e+00\n",
      "Epoch 67/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8160 - val_loss: 0.0593 - val_custom_f1: 0.0000e+00\n",
      "Epoch 68/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0375 - custom_f1: 0.8054 - val_loss: 0.0625 - val_custom_f1: 0.0000e+00\n",
      "Epoch 69/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8180 - val_loss: 0.0659 - val_custom_f1: 0.0000e+00\n",
      "Epoch 70/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8190 - val_loss: 0.0617 - val_custom_f1: 0.0000e+00\n",
      "Epoch 71/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8159 - val_loss: 0.0569 - val_custom_f1: 0.0000e+00\n",
      "Epoch 72/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - custom_f1: 0.7961 - val_loss: 0.0528 - val_custom_f1: 0.0000e+00\n",
      "Epoch 73/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8113 - val_loss: 0.0525 - val_custom_f1: 0.0000e+00\n",
      "Epoch 74/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8317 - val_loss: 0.0570 - val_custom_f1: 0.0000e+00\n",
      "Epoch 75/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0345 - custom_f1: 0.8080 - val_loss: 0.0587 - val_custom_f1: 0.0000e+00\n",
      "Epoch 76/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - custom_f1: 0.8227 - val_loss: 0.0535 - val_custom_f1: 0.0000e+00\n",
      "Epoch 77/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.7994 - val_loss: 0.0505 - val_custom_f1: 0.0000e+00\n",
      "Epoch 78/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.7893 - val_loss: 0.0508 - val_custom_f1: 0.0000e+00\n",
      "Epoch 79/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0383 - custom_f1: 0.8177 - val_loss: 0.0539 - val_custom_f1: 0.0000e+00\n",
      "Epoch 80/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0376 - custom_f1: 0.8132 - val_loss: 0.0526 - val_custom_f1: 0.0000e+00\n",
      "Epoch 81/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - custom_f1: 0.8242 - val_loss: 0.0493 - val_custom_f1: 0.0000e+00\n",
      "Epoch 82/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.7804 - val_loss: 0.0495 - val_custom_f1: 0.0000e+00\n",
      "Epoch 83/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8423 - val_loss: 0.0522 - val_custom_f1: 0.0000e+00\n",
      "Epoch 84/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0390 - custom_f1: 0.8061 - val_loss: 0.0556 - val_custom_f1: 0.0000e+00\n",
      "Epoch 85/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0399 - custom_f1: 0.7889 - val_loss: 0.0563 - val_custom_f1: 0.0000e+00\n",
      "Epoch 86/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0377 - custom_f1: 0.8132 - val_loss: 0.0494 - val_custom_f1: 0.0000e+00\n",
      "Epoch 87/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.7884 - val_loss: 0.0465 - val_custom_f1: 0.8158\n",
      "Epoch 88/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8034 - val_loss: 0.0470 - val_custom_f1: 0.0000e+00\n",
      "Epoch 89/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8041 - val_loss: 0.0465 - val_custom_f1: 0.0000e+00\n",
      "Epoch 90/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.7778 - val_loss: 0.0455 - val_custom_f1: 0.0000e+00\n",
      "Epoch 91/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8085 - val_loss: 0.0456 - val_custom_f1: 0.0000e+00\n",
      "Epoch 92/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8301 - val_loss: 0.0462 - val_custom_f1: 0.0000e+00\n",
      "Epoch 93/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8154 - val_loss: 0.0433 - val_custom_f1: 0.8079\n",
      "Epoch 94/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - custom_f1: 0.8211 - val_loss: 0.0410 - val_custom_f1: 0.8158\n",
      "Epoch 95/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8076 - val_loss: 0.0430 - val_custom_f1: 0.8158\n",
      "Epoch 96/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8230 - val_loss: 0.0425 - val_custom_f1: 0.8158\n",
      "Epoch 97/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8117 - val_loss: 0.0409 - val_custom_f1: 0.8158\n",
      "Epoch 98/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0380 - custom_f1: 0.8196 - val_loss: 0.0404 - val_custom_f1: 0.8158\n",
      "Epoch 99/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.7798 - val_loss: 0.0393 - val_custom_f1: 0.8158\n",
      "Epoch 100/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.7940 - val_loss: 0.0404 - val_custom_f1: 0.8158\n",
      "Epoch 101/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0377 - custom_f1: 0.8204 - val_loss: 0.0411 - val_custom_f1: 0.8158\n",
      "Epoch 102/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8147 - val_loss: 0.0417 - val_custom_f1: 0.8158\n",
      "Epoch 103/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8237 - val_loss: 0.0387 - val_custom_f1: 0.8158\n",
      "Epoch 104/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.7979 - val_loss: 0.0373 - val_custom_f1: 0.8158\n",
      "Epoch 105/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8325 - val_loss: 0.0400 - val_custom_f1: 0.8158\n",
      "Epoch 106/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.7730 - val_loss: 0.0431 - val_custom_f1: 0.8158\n",
      "Epoch 107/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.7662 - val_loss: 0.0424 - val_custom_f1: 0.8158\n",
      "Epoch 108/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.7824 - val_loss: 0.0384 - val_custom_f1: 0.8158\n",
      "Epoch 109/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.7914 - val_loss: 0.0353 - val_custom_f1: 0.8158\n",
      "Epoch 110/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8315 - val_loss: 0.0369 - val_custom_f1: 0.8158\n",
      "Epoch 111/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8151 - val_loss: 0.0417 - val_custom_f1: 0.8158\n",
      "Epoch 112/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8140 - val_loss: 0.0430 - val_custom_f1: 0.8158\n",
      "Epoch 113/725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8188 - val_loss: 0.0383 - val_custom_f1: 0.8158\n",
      "Epoch 114/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8025 - val_loss: 0.0357 - val_custom_f1: 0.8182\n",
      "Epoch 115/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8068 - val_loss: 0.0380 - val_custom_f1: 0.8105\n",
      "Epoch 116/725\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0353 - custom_f1: 0.7791 - val_loss: 0.0410 - val_custom_f1: 0.8158\n",
      "Epoch 117/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8088 - val_loss: 0.0384 - val_custom_f1: 0.8158\n",
      "Epoch 118/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0380 - custom_f1: 0.8154 - val_loss: 0.0362 - val_custom_f1: 0.8182\n",
      "Epoch 119/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7993 - val_loss: 0.0370 - val_custom_f1: 0.8182\n",
      "Epoch 120/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.7969 - val_loss: 0.0364 - val_custom_f1: 0.8235\n",
      "Epoch 121/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0338 - custom_f1: 0.8109 - val_loss: 0.0362 - val_custom_f1: 0.8158\n",
      "Epoch 122/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - custom_f1: 0.7730 - val_loss: 0.0363 - val_custom_f1: 0.8158\n",
      "Epoch 123/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0344 - custom_f1: 0.8077 - val_loss: 0.0368 - val_custom_f1: 0.8158\n",
      "Epoch 124/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0336 - custom_f1: 0.8230 - val_loss: 0.0368 - val_custom_f1: 0.8158\n",
      "Epoch 125/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.7794 - val_loss: 0.0355 - val_custom_f1: 0.8105\n",
      "Epoch 126/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8121 - val_loss: 0.0359 - val_custom_f1: 0.8158\n",
      "Epoch 127/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0362 - custom_f1: 0.7838 - val_loss: 0.0364 - val_custom_f1: 0.8158\n",
      "Epoch 128/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8138 - val_loss: 0.0355 - val_custom_f1: 0.8158\n",
      "Epoch 129/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.7985 - val_loss: 0.0355 - val_custom_f1: 0.8158\n",
      "Epoch 130/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8165 - val_loss: 0.0356 - val_custom_f1: 0.8158\n",
      "Epoch 131/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.7951 - val_loss: 0.0358 - val_custom_f1: 0.8158\n",
      "Epoch 132/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8170 - val_loss: 0.0369 - val_custom_f1: 0.8158\n",
      "Epoch 133/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8246 - val_loss: 0.0384 - val_custom_f1: 0.8158\n",
      "Epoch 134/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8083 - val_loss: 0.0355 - val_custom_f1: 0.8235\n",
      "Epoch 135/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0364 - custom_f1: 0.8211 - val_loss: 0.0345 - val_custom_f1: 0.8235\n",
      "Epoch 136/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8161 - val_loss: 0.0353 - val_custom_f1: 0.8235\n",
      "Epoch 137/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.7930 - val_loss: 0.0356 - val_custom_f1: 0.8235\n",
      "Epoch 138/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8383 - val_loss: 0.0351 - val_custom_f1: 0.8235\n",
      "Epoch 139/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8289 - val_loss: 0.0347 - val_custom_f1: 0.8235\n",
      "Epoch 140/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8338 - val_loss: 0.0337 - val_custom_f1: 0.8235\n",
      "Epoch 141/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7882 - val_loss: 0.0358 - val_custom_f1: 0.8235\n",
      "Epoch 142/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8115 - val_loss: 0.0365 - val_custom_f1: 0.8235\n",
      "Epoch 143/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.7708 - val_loss: 0.0352 - val_custom_f1: 0.8235\n",
      "Epoch 144/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0336 - custom_f1: 0.8123 - val_loss: 0.0341 - val_custom_f1: 0.8235\n",
      "Epoch 145/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - custom_f1: 0.8060 - val_loss: 0.0340 - val_custom_f1: 0.8235\n",
      "Epoch 146/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8254 - val_loss: 0.0358 - val_custom_f1: 0.8235\n",
      "Epoch 147/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8144 - val_loss: 0.0363 - val_custom_f1: 0.8235\n",
      "Epoch 148/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8206 - val_loss: 0.0348 - val_custom_f1: 0.8235\n",
      "Epoch 149/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0338 - custom_f1: 0.7997 - val_loss: 0.0358 - val_custom_f1: 0.8235\n",
      "Epoch 150/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8245 - val_loss: 0.0384 - val_custom_f1: 0.8158\n",
      "Epoch 151/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8112 - val_loss: 0.0362 - val_custom_f1: 0.8158\n",
      "Epoch 152/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0339 - custom_f1: 0.8197 - val_loss: 0.0347 - val_custom_f1: 0.8258\n",
      "Epoch 153/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8158 - val_loss: 0.0347 - val_custom_f1: 0.8408\n",
      "Epoch 154/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.8583 - val_loss: 0.0372 - val_custom_f1: 0.8182\n",
      "Epoch 155/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8193 - val_loss: 0.0377 - val_custom_f1: 0.8182\n",
      "Epoch 156/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8001 - val_loss: 0.0345 - val_custom_f1: 0.8408\n",
      "Epoch 157/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8297 - val_loss: 0.0358 - val_custom_f1: 0.8258\n",
      "Epoch 158/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0347 - custom_f1: 0.7929 - val_loss: 0.0394 - val_custom_f1: 0.8158\n",
      "Epoch 159/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0345 - custom_f1: 0.8207 - val_loss: 0.0381 - val_custom_f1: 0.8158\n",
      "Epoch 160/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0363 - custom_f1: 0.8155 - val_loss: 0.0371 - val_custom_f1: 0.8182\n",
      "Epoch 161/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.7926 - val_loss: 0.0358 - val_custom_f1: 0.8258\n",
      "Epoch 162/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8122 - val_loss: 0.0347 - val_custom_f1: 0.8553\n",
      "Epoch 163/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8144 - val_loss: 0.0355 - val_custom_f1: 0.8553\n",
      "Epoch 164/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8027 - val_loss: 0.0360 - val_custom_f1: 0.8258\n",
      "Epoch 165/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - custom_f1: 0.8336 - val_loss: 0.0341 - val_custom_f1: 0.8553\n",
      "Epoch 166/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8070 - val_loss: 0.0339 - val_custom_f1: 0.8258\n",
      "Epoch 167/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8038 - val_loss: 0.0337 - val_custom_f1: 0.8312\n",
      "Epoch 168/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8081 - val_loss: 0.0335 - val_custom_f1: 0.8312\n",
      "Epoch 169/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0338 - custom_f1: 0.8124 - val_loss: 0.0349 - val_custom_f1: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8428 - val_loss: 0.0351 - val_custom_f1: 0.8158\n",
      "Epoch 171/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8174 - val_loss: 0.0348 - val_custom_f1: 0.8235\n",
      "Epoch 172/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.7817 - val_loss: 0.0333 - val_custom_f1: 0.8235\n",
      "Epoch 173/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0341 - custom_f1: 0.8205 - val_loss: 0.0331 - val_custom_f1: 0.8625\n",
      "Epoch 174/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.7981 - val_loss: 0.0337 - val_custom_f1: 0.8258\n",
      "Epoch 175/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8038 - val_loss: 0.0348 - val_custom_f1: 0.8235\n",
      "Epoch 176/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8201 - val_loss: 0.0345 - val_custom_f1: 0.8258\n",
      "Epoch 177/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.7760 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 178/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8143 - val_loss: 0.0340 - val_custom_f1: 0.8625\n",
      "Epoch 179/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8073 - val_loss: 0.0337 - val_custom_f1: 0.8625\n",
      "Epoch 180/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - custom_f1: 0.7975 - val_loss: 0.0340 - val_custom_f1: 0.8625\n",
      "Epoch 181/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8201 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 182/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8093 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 183/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8065 - val_loss: 0.0341 - val_custom_f1: 0.8553\n",
      "Epoch 184/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0337 - custom_f1: 0.7957 - val_loss: 0.0346 - val_custom_f1: 0.8625\n",
      "Epoch 185/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8106 - val_loss: 0.0342 - val_custom_f1: 0.8553\n",
      "Epoch 186/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8111 - val_loss: 0.0349 - val_custom_f1: 0.8235\n",
      "Epoch 187/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8162 - val_loss: 0.0364 - val_custom_f1: 0.8235\n",
      "Epoch 188/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8295 - val_loss: 0.0348 - val_custom_f1: 0.8235\n",
      "Epoch 189/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - custom_f1: 0.8195 - val_loss: 0.0343 - val_custom_f1: 0.8387\n",
      "Epoch 190/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8152 - val_loss: 0.0343 - val_custom_f1: 0.8235\n",
      "Epoch 191/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7935 - val_loss: 0.0342 - val_custom_f1: 0.8235\n",
      "Epoch 192/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8025 - val_loss: 0.0353 - val_custom_f1: 0.8235\n",
      "Epoch 193/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.8068 - val_loss: 0.0352 - val_custom_f1: 0.8158\n",
      "Epoch 194/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8084 - val_loss: 0.0349 - val_custom_f1: 0.8235\n",
      "Epoch 195/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0388 - custom_f1: 0.8014 - val_loss: 0.0330 - val_custom_f1: 0.8481\n",
      "Epoch 196/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.7897 - val_loss: 0.0328 - val_custom_f1: 0.8481\n",
      "Epoch 197/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8333 - val_loss: 0.0340 - val_custom_f1: 0.8235\n",
      "Epoch 198/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8295 - val_loss: 0.0350 - val_custom_f1: 0.8235\n",
      "Epoch 199/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8126 - val_loss: 0.0332 - val_custom_f1: 0.8553\n",
      "Epoch 200/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8162 - val_loss: 0.0333 - val_custom_f1: 0.8553\n",
      "Epoch 201/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8182 - val_loss: 0.0341 - val_custom_f1: 0.8553\n",
      "Epoch 202/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0366 - custom_f1: 0.8229 - val_loss: 0.0335 - val_custom_f1: 0.8553\n",
      "Epoch 203/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.8361 - val_loss: 0.0337 - val_custom_f1: 0.8553\n",
      "Epoch 204/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8147 - val_loss: 0.0340 - val_custom_f1: 0.8553\n",
      "Epoch 205/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.8299 - val_loss: 0.0329 - val_custom_f1: 0.8553\n",
      "Epoch 206/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8191 - val_loss: 0.0334 - val_custom_f1: 0.8553\n",
      "Epoch 207/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8263 - val_loss: 0.0352 - val_custom_f1: 0.8182\n",
      "Epoch 208/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8331 - val_loss: 0.0355 - val_custom_f1: 0.8235\n",
      "Epoch 209/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8118 - val_loss: 0.0340 - val_custom_f1: 0.8481\n",
      "Epoch 210/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - custom_f1: 0.8065 - val_loss: 0.0337 - val_custom_f1: 0.8481\n",
      "Epoch 211/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8072 - val_loss: 0.0339 - val_custom_f1: 0.8235\n",
      "Epoch 212/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8018 - val_loss: 0.0346 - val_custom_f1: 0.8158\n",
      "Epoch 213/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8119 - val_loss: 0.0351 - val_custom_f1: 0.8158\n",
      "Epoch 214/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8328 - val_loss: 0.0343 - val_custom_f1: 0.8387\n",
      "Epoch 215/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8316 - val_loss: 0.0338 - val_custom_f1: 0.8553\n",
      "Epoch 216/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - custom_f1: 0.8313 - val_loss: 0.0353 - val_custom_f1: 0.8235\n",
      "Epoch 217/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.7959 - val_loss: 0.0344 - val_custom_f1: 0.8235\n",
      "Epoch 218/725\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0353 - custom_f1: 0.7945 - val_loss: 0.0328 - val_custom_f1: 0.8608\n",
      "Epoch 219/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - custom_f1: 0.8473 - val_loss: 0.0348 - val_custom_f1: 0.8462\n",
      "Epoch 220/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - custom_f1: 0.8216 - val_loss: 0.0334 - val_custom_f1: 0.8625\n",
      "Epoch 221/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0337 - custom_f1: 0.8334 - val_loss: 0.0328 - val_custom_f1: 0.8625\n",
      "Epoch 222/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - custom_f1: 0.8403 - val_loss: 0.0337 - val_custom_f1: 0.8625\n",
      "Epoch 223/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8291 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 224/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8216 - val_loss: 0.0329 - val_custom_f1: 0.8553\n",
      "Epoch 225/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.8229 - val_loss: 0.0332 - val_custom_f1: 0.8608\n",
      "Epoch 226/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8169 - val_loss: 0.0341 - val_custom_f1: 0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.7939 - val_loss: 0.0332 - val_custom_f1: 0.8312\n",
      "Epoch 228/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - custom_f1: 0.8084 - val_loss: 0.0332 - val_custom_f1: 0.8553\n",
      "Epoch 229/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8374 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 230/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0341 - custom_f1: 0.8149 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 231/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8264 - val_loss: 0.0340 - val_custom_f1: 0.8553\n",
      "Epoch 232/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0325 - custom_f1: 0.8394 - val_loss: 0.0353 - val_custom_f1: 0.8312\n",
      "Epoch 233/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8035 - val_loss: 0.0330 - val_custom_f1: 0.8553\n",
      "Epoch 234/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8073 - val_loss: 0.0334 - val_custom_f1: 0.8553\n",
      "Epoch 235/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8372 - val_loss: 0.0362 - val_custom_f1: 0.8333\n",
      "Epoch 236/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8365 - val_loss: 0.0344 - val_custom_f1: 0.8182\n",
      "Epoch 237/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8088 - val_loss: 0.0347 - val_custom_f1: 0.8235\n",
      "Epoch 238/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.7994 - val_loss: 0.0338 - val_custom_f1: 0.8553\n",
      "Epoch 239/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - custom_f1: 0.7700 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 240/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8033 - val_loss: 0.0338 - val_custom_f1: 0.8553\n",
      "Epoch 241/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.7993 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 242/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8130 - val_loss: 0.0338 - val_custom_f1: 0.8642\n",
      "Epoch 243/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0332 - custom_f1: 0.7970 - val_loss: 0.0344 - val_custom_f1: 0.8553\n",
      "Epoch 244/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8053 - val_loss: 0.0335 - val_custom_f1: 0.8608\n",
      "Epoch 245/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8061 - val_loss: 0.0330 - val_custom_f1: 0.8553\n",
      "Epoch 246/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8253 - val_loss: 0.0354 - val_custom_f1: 0.8235\n",
      "Epoch 247/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8426 - val_loss: 0.0350 - val_custom_f1: 0.8235\n",
      "Epoch 248/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8074 - val_loss: 0.0345 - val_custom_f1: 0.8235\n",
      "Epoch 249/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8182 - val_loss: 0.0363 - val_custom_f1: 0.8235\n",
      "Epoch 250/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.8223 - val_loss: 0.0364 - val_custom_f1: 0.8235\n",
      "Epoch 251/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8155 - val_loss: 0.0342 - val_custom_f1: 0.8387\n",
      "Epoch 252/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.7988 - val_loss: 0.0345 - val_custom_f1: 0.8235\n",
      "Epoch 253/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8067 - val_loss: 0.0350 - val_custom_f1: 0.8235\n",
      "Epoch 254/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8141 - val_loss: 0.0363 - val_custom_f1: 0.8235\n",
      "Epoch 255/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8080 - val_loss: 0.0337 - val_custom_f1: 0.8553\n",
      "Epoch 256/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.7858 - val_loss: 0.0339 - val_custom_f1: 0.8481\n",
      "Epoch 257/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8002 - val_loss: 0.0370 - val_custom_f1: 0.8235\n",
      "Epoch 258/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.8218 - val_loss: 0.0368 - val_custom_f1: 0.8235\n",
      "Epoch 259/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8115 - val_loss: 0.0347 - val_custom_f1: 0.8696\n",
      "Epoch 260/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8305 - val_loss: 0.0367 - val_custom_f1: 0.8642\n",
      "Epoch 261/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8200 - val_loss: 0.0361 - val_custom_f1: 0.8333\n",
      "Epoch 262/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8089 - val_loss: 0.0377 - val_custom_f1: 0.8235\n",
      "Epoch 263/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8276 - val_loss: 0.0358 - val_custom_f1: 0.8182\n",
      "Epoch 264/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8224 - val_loss: 0.0352 - val_custom_f1: 0.8182\n",
      "Epoch 265/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.7719 - val_loss: 0.0357 - val_custom_f1: 0.8235\n",
      "Epoch 266/725\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0354 - custom_f1: 0.8026 - val_loss: 0.0359 - val_custom_f1: 0.8235\n",
      "Epoch 267/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.8153 - val_loss: 0.0363 - val_custom_f1: 0.8235\n",
      "Epoch 268/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8114 - val_loss: 0.0353 - val_custom_f1: 0.8235\n",
      "Epoch 269/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8112 - val_loss: 0.0345 - val_custom_f1: 0.8182\n",
      "Epoch 270/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0333 - custom_f1: 0.8305 - val_loss: 0.0357 - val_custom_f1: 0.8235\n",
      "Epoch 271/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8144 - val_loss: 0.0350 - val_custom_f1: 0.8235\n",
      "Epoch 272/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.7917 - val_loss: 0.0341 - val_custom_f1: 0.8258\n",
      "Epoch 273/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8241 - val_loss: 0.0347 - val_custom_f1: 0.8553\n",
      "Epoch 274/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8239 - val_loss: 0.0354 - val_custom_f1: 0.8235\n",
      "Epoch 275/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8163 - val_loss: 0.0354 - val_custom_f1: 0.8235\n",
      "Epoch 276/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8061 - val_loss: 0.0351 - val_custom_f1: 0.8235\n",
      "Epoch 277/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8216 - val_loss: 0.0375 - val_custom_f1: 0.8235\n",
      "Epoch 278/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8091 - val_loss: 0.0368 - val_custom_f1: 0.8235\n",
      "Epoch 279/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8155 - val_loss: 0.0353 - val_custom_f1: 0.8235\n",
      "Epoch 280/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.8192 - val_loss: 0.0358 - val_custom_f1: 0.8182\n",
      "Epoch 281/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8199 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 282/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7878 - val_loss: 0.0350 - val_custom_f1: 0.8481\n",
      "Epoch 283/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0344 - custom_f1: 0.8231 - val_loss: 0.0352 - val_custom_f1: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0361 - custom_f1: 0.8077 - val_loss: 0.0358 - val_custom_f1: 0.8182\n",
      "Epoch 285/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.7808 - val_loss: 0.0358 - val_custom_f1: 0.8235\n",
      "Epoch 286/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0345 - custom_f1: 0.8232 - val_loss: 0.0347 - val_custom_f1: 0.8312\n",
      "Epoch 287/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0344 - custom_f1: 0.8209 - val_loss: 0.0356 - val_custom_f1: 0.8462\n",
      "Epoch 288/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8444 - val_loss: 0.0381 - val_custom_f1: 0.8235\n",
      "Epoch 289/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8308 - val_loss: 0.0354 - val_custom_f1: 0.8235\n",
      "Epoch 290/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8199 - val_loss: 0.0348 - val_custom_f1: 0.8333\n",
      "Epoch 291/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - custom_f1: 0.8263 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 292/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8266 - val_loss: 0.0348 - val_custom_f1: 0.8625\n",
      "Epoch 293/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0323 - custom_f1: 0.8262 - val_loss: 0.0363 - val_custom_f1: 0.8408\n",
      "Epoch 294/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0338 - custom_f1: 0.8056 - val_loss: 0.0357 - val_custom_f1: 0.8258\n",
      "Epoch 295/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0337 - custom_f1: 0.7972 - val_loss: 0.0344 - val_custom_f1: 0.8481\n",
      "Epoch 296/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0345 - custom_f1: 0.8026 - val_loss: 0.0344 - val_custom_f1: 0.8625\n",
      "Epoch 297/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8153 - val_loss: 0.0344 - val_custom_f1: 0.8625\n",
      "Epoch 298/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.8020 - val_loss: 0.0352 - val_custom_f1: 0.8481\n",
      "Epoch 299/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8075 - val_loss: 0.0356 - val_custom_f1: 0.8481\n",
      "Epoch 300/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8163 - val_loss: 0.0344 - val_custom_f1: 0.8481\n",
      "Epoch 301/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8191 - val_loss: 0.0338 - val_custom_f1: 0.8553\n",
      "Epoch 302/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.8364 - val_loss: 0.0336 - val_custom_f1: 0.8408\n",
      "Epoch 303/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0346 - custom_f1: 0.8197 - val_loss: 0.0337 - val_custom_f1: 0.8481\n",
      "Epoch 304/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8023 - val_loss: 0.0336 - val_custom_f1: 0.8553\n",
      "Epoch 305/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.7795 - val_loss: 0.0333 - val_custom_f1: 0.8553\n",
      "Epoch 306/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8189 - val_loss: 0.0338 - val_custom_f1: 0.8553\n",
      "Epoch 307/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8089 - val_loss: 0.0335 - val_custom_f1: 0.8625\n",
      "Epoch 308/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.7910 - val_loss: 0.0332 - val_custom_f1: 0.8553\n",
      "Epoch 309/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - custom_f1: 0.8357 - val_loss: 0.0360 - val_custom_f1: 0.8182\n",
      "Epoch 310/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8179 - val_loss: 0.0351 - val_custom_f1: 0.8258\n",
      "Epoch 311/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0377 - custom_f1: 0.8148 - val_loss: 0.0341 - val_custom_f1: 0.8553\n",
      "Epoch 312/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0375 - custom_f1: 0.8091 - val_loss: 0.0344 - val_custom_f1: 0.8553\n",
      "Epoch 313/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8221 - val_loss: 0.0349 - val_custom_f1: 0.8182\n",
      "Epoch 314/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8148 - val_loss: 0.0352 - val_custom_f1: 0.8158\n",
      "Epoch 315/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8138 - val_loss: 0.0345 - val_custom_f1: 0.8235\n",
      "Epoch 316/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8176 - val_loss: 0.0338 - val_custom_f1: 0.8333\n",
      "Epoch 317/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8274 - val_loss: 0.0344 - val_custom_f1: 0.8182\n",
      "Epoch 318/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8139 - val_loss: 0.0347 - val_custom_f1: 0.8258\n",
      "Epoch 319/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8420 - val_loss: 0.0336 - val_custom_f1: 0.8408\n",
      "Epoch 320/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8341 - val_loss: 0.0360 - val_custom_f1: 0.8481\n",
      "Epoch 321/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - custom_f1: 0.8298 - val_loss: 0.0357 - val_custom_f1: 0.8408\n",
      "Epoch 322/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8060 - val_loss: 0.0338 - val_custom_f1: 0.8408\n",
      "Epoch 323/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8015 - val_loss: 0.0332 - val_custom_f1: 0.8553\n",
      "Epoch 324/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - custom_f1: 0.8333 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 325/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8140 - val_loss: 0.0330 - val_custom_f1: 0.8625\n",
      "Epoch 326/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.7977 - val_loss: 0.0327 - val_custom_f1: 0.8625\n",
      "Epoch 327/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8074 - val_loss: 0.0338 - val_custom_f1: 0.8625\n",
      "Epoch 328/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7895 - val_loss: 0.0327 - val_custom_f1: 0.8625\n",
      "Epoch 329/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.7946 - val_loss: 0.0323 - val_custom_f1: 0.8625\n",
      "Epoch 330/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8105 - val_loss: 0.0332 - val_custom_f1: 0.8333\n",
      "Epoch 331/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - custom_f1: 0.8320 - val_loss: 0.0337 - val_custom_f1: 0.8408\n",
      "Epoch 332/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.7979 - val_loss: 0.0321 - val_custom_f1: 0.8481\n",
      "Epoch 333/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8316 - val_loss: 0.0323 - val_custom_f1: 0.8696\n",
      "Epoch 334/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8242 - val_loss: 0.0346 - val_custom_f1: 0.8481\n",
      "Epoch 335/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0375 - custom_f1: 0.8328 - val_loss: 0.0351 - val_custom_f1: 0.8481\n",
      "Epoch 336/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.7992 - val_loss: 0.0335 - val_custom_f1: 0.8333\n",
      "Epoch 337/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.7647 - val_loss: 0.0326 - val_custom_f1: 0.8625\n",
      "Epoch 338/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8241 - val_loss: 0.0337 - val_custom_f1: 0.8589\n",
      "Epoch 339/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0341 - custom_f1: 0.8098 - val_loss: 0.0339 - val_custom_f1: 0.8571\n",
      "Epoch 340/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8333 - val_loss: 0.0341 - val_custom_f1: 0.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8418 - val_loss: 0.0350 - val_custom_f1: 0.8589\n",
      "Epoch 342/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0336 - custom_f1: 0.8425 - val_loss: 0.0349 - val_custom_f1: 0.8642\n",
      "Epoch 343/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0335 - custom_f1: 0.8066 - val_loss: 0.0341 - val_custom_f1: 0.8642\n",
      "Epoch 344/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8100 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 345/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.7971 - val_loss: 0.0361 - val_custom_f1: 0.8408\n",
      "Epoch 346/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8190 - val_loss: 0.0352 - val_custom_f1: 0.8553\n",
      "Epoch 347/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8040 - val_loss: 0.0351 - val_custom_f1: 0.8553\n",
      "Epoch 348/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0368 - custom_f1: 0.8213 - val_loss: 0.0353 - val_custom_f1: 0.8258\n",
      "Epoch 349/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8207 - val_loss: 0.0368 - val_custom_f1: 0.8182\n",
      "Epoch 350/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8336 - val_loss: 0.0350 - val_custom_f1: 0.8553\n",
      "Epoch 351/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.7982 - val_loss: 0.0334 - val_custom_f1: 0.8553\n",
      "Epoch 352/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8373 - val_loss: 0.0353 - val_custom_f1: 0.8258\n",
      "Epoch 353/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8082 - val_loss: 0.0371 - val_custom_f1: 0.8182\n",
      "Epoch 354/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.8154 - val_loss: 0.0332 - val_custom_f1: 0.8553\n",
      "Epoch 355/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - custom_f1: 0.8255 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 356/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8378 - val_loss: 0.0348 - val_custom_f1: 0.8625\n",
      "Epoch 357/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.8015 - val_loss: 0.0335 - val_custom_f1: 0.8481\n",
      "Epoch 358/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8017 - val_loss: 0.0335 - val_custom_f1: 0.8333\n",
      "Epoch 359/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8059 - val_loss: 0.0358 - val_custom_f1: 0.8333\n",
      "Epoch 360/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8076 - val_loss: 0.0353 - val_custom_f1: 0.8408\n",
      "Epoch 361/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8295 - val_loss: 0.0341 - val_custom_f1: 0.8553\n",
      "Epoch 362/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8369 - val_loss: 0.0350 - val_custom_f1: 0.8408\n",
      "Epoch 363/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.7965 - val_loss: 0.0362 - val_custom_f1: 0.8333\n",
      "Epoch 364/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8190 - val_loss: 0.0350 - val_custom_f1: 0.8333\n",
      "Epoch 365/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.7912 - val_loss: 0.0353 - val_custom_f1: 0.8258\n",
      "Epoch 366/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8160 - val_loss: 0.0380 - val_custom_f1: 0.8182\n",
      "Epoch 367/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8100 - val_loss: 0.0352 - val_custom_f1: 0.8258\n",
      "Epoch 368/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - custom_f1: 0.7881 - val_loss: 0.0349 - val_custom_f1: 0.8333\n",
      "Epoch 369/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8234 - val_loss: 0.0356 - val_custom_f1: 0.8408\n",
      "Epoch 370/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8163 - val_loss: 0.0354 - val_custom_f1: 0.8553\n",
      "Epoch 371/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8081 - val_loss: 0.0352 - val_custom_f1: 0.8553\n",
      "Epoch 372/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8398 - val_loss: 0.0374 - val_custom_f1: 0.8553\n",
      "Epoch 373/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8272 - val_loss: 0.0373 - val_custom_f1: 0.8481\n",
      "Epoch 374/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8202 - val_loss: 0.0351 - val_custom_f1: 0.8553\n",
      "Epoch 375/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.7995 - val_loss: 0.0360 - val_custom_f1: 0.8333\n",
      "Epoch 376/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8240 - val_loss: 0.0364 - val_custom_f1: 0.8333\n",
      "Epoch 377/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0347 - custom_f1: 0.8131 - val_loss: 0.0342 - val_custom_f1: 0.8625\n",
      "Epoch 378/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8015 - val_loss: 0.0342 - val_custom_f1: 0.8625\n",
      "Epoch 379/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - custom_f1: 0.8100 - val_loss: 0.0356 - val_custom_f1: 0.8408\n",
      "Epoch 380/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8240 - val_loss: 0.0362 - val_custom_f1: 0.8553\n",
      "Epoch 381/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8024 - val_loss: 0.0371 - val_custom_f1: 0.8408\n",
      "Epoch 382/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0336 - custom_f1: 0.8121 - val_loss: 0.0384 - val_custom_f1: 0.8182\n",
      "Epoch 383/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8288 - val_loss: 0.0374 - val_custom_f1: 0.8408\n",
      "Epoch 384/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8330 - val_loss: 0.0362 - val_custom_f1: 0.8553\n",
      "Epoch 385/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0336 - custom_f1: 0.8255 - val_loss: 0.0359 - val_custom_f1: 0.8408\n",
      "Epoch 386/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8380 - val_loss: 0.0397 - val_custom_f1: 0.8182\n",
      "Epoch 387/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0337 - custom_f1: 0.8199 - val_loss: 0.0380 - val_custom_f1: 0.8182\n",
      "Epoch 388/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0363 - custom_f1: 0.8361 - val_loss: 0.0353 - val_custom_f1: 0.8553\n",
      "Epoch 389/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0357 - custom_f1: 0.8109 - val_loss: 0.0350 - val_custom_f1: 0.8625\n",
      "Epoch 390/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0333 - custom_f1: 0.8302 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 391/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0341 - custom_f1: 0.8267 - val_loss: 0.0353 - val_custom_f1: 0.8333\n",
      "Epoch 392/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8008 - val_loss: 0.0355 - val_custom_f1: 0.8333\n",
      "Epoch 393/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - custom_f1: 0.8240 - val_loss: 0.0361 - val_custom_f1: 0.8625\n",
      "Epoch 394/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8506 - val_loss: 0.0365 - val_custom_f1: 0.8625\n",
      "Epoch 395/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8035 - val_loss: 0.0354 - val_custom_f1: 0.8553\n",
      "Epoch 396/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8096 - val_loss: 0.0353 - val_custom_f1: 0.8553\n",
      "Epoch 397/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8188 - val_loss: 0.0356 - val_custom_f1: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8251 - val_loss: 0.0345 - val_custom_f1: 0.8625\n",
      "Epoch 399/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0336 - custom_f1: 0.8302 - val_loss: 0.0346 - val_custom_f1: 0.8625\n",
      "Epoch 400/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0329 - custom_f1: 0.8338 - val_loss: 0.0361 - val_custom_f1: 0.8625\n",
      "Epoch 401/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8281 - val_loss: 0.0348 - val_custom_f1: 0.8625\n",
      "Epoch 402/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8030 - val_loss: 0.0350 - val_custom_f1: 0.8625\n",
      "Epoch 403/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8310 - val_loss: 0.0350 - val_custom_f1: 0.8625\n",
      "Epoch 404/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - custom_f1: 0.8185 - val_loss: 0.0342 - val_custom_f1: 0.8625\n",
      "Epoch 405/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8044 - val_loss: 0.0352 - val_custom_f1: 0.8481\n",
      "Epoch 406/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8238 - val_loss: 0.0345 - val_custom_f1: 0.8625\n",
      "Epoch 407/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8260 - val_loss: 0.0350 - val_custom_f1: 0.8571\n",
      "Epoch 408/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0373 - custom_f1: 0.8072 - val_loss: 0.0340 - val_custom_f1: 0.8625\n",
      "Epoch 409/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - custom_f1: 0.8258 - val_loss: 0.0362 - val_custom_f1: 0.8258\n",
      "Epoch 410/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0377 - custom_f1: 0.8494 - val_loss: 0.0345 - val_custom_f1: 0.8481\n",
      "Epoch 411/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0390 - custom_f1: 0.8049 - val_loss: 0.0329 - val_custom_f1: 0.8625\n",
      "Epoch 412/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8260 - val_loss: 0.0329 - val_custom_f1: 0.8625\n",
      "Epoch 413/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0349 - custom_f1: 0.8149 - val_loss: 0.0344 - val_custom_f1: 0.8625\n",
      "Epoch 414/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.7771 - val_loss: 0.0346 - val_custom_f1: 0.8553\n",
      "Epoch 415/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.7947 - val_loss: 0.0342 - val_custom_f1: 0.8553\n",
      "Epoch 416/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8147 - val_loss: 0.0351 - val_custom_f1: 0.8481\n",
      "Epoch 417/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8251 - val_loss: 0.0373 - val_custom_f1: 0.8182\n",
      "Epoch 418/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8084 - val_loss: 0.0349 - val_custom_f1: 0.8235\n",
      "Epoch 419/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.7888 - val_loss: 0.0355 - val_custom_f1: 0.8235\n",
      "Epoch 420/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8213 - val_loss: 0.0361 - val_custom_f1: 0.8235\n",
      "Epoch 421/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8316 - val_loss: 0.0347 - val_custom_f1: 0.8258\n",
      "Epoch 422/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8257 - val_loss: 0.0346 - val_custom_f1: 0.8258\n",
      "Epoch 423/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0338 - custom_f1: 0.8098 - val_loss: 0.0360 - val_custom_f1: 0.8258\n",
      "Epoch 424/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0376 - custom_f1: 0.7951 - val_loss: 0.0345 - val_custom_f1: 0.8333\n",
      "Epoch 425/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8333 - val_loss: 0.0341 - val_custom_f1: 0.8408\n",
      "Epoch 426/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8038 - val_loss: 0.0353 - val_custom_f1: 0.8333\n",
      "Epoch 427/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.8147 - val_loss: 0.0357 - val_custom_f1: 0.8258\n",
      "Epoch 428/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8297 - val_loss: 0.0345 - val_custom_f1: 0.8333\n",
      "Epoch 429/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8047 - val_loss: 0.0351 - val_custom_f1: 0.8333\n",
      "Epoch 430/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0346 - custom_f1: 0.8052 - val_loss: 0.0362 - val_custom_f1: 0.8182\n",
      "Epoch 431/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8244 - val_loss: 0.0353 - val_custom_f1: 0.8258\n",
      "Epoch 432/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0340 - custom_f1: 0.8071 - val_loss: 0.0354 - val_custom_f1: 0.8312\n",
      "Epoch 433/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0343 - custom_f1: 0.8366 - val_loss: 0.0364 - val_custom_f1: 0.8235\n",
      "Epoch 434/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8403 - val_loss: 0.0364 - val_custom_f1: 0.8235\n",
      "Epoch 435/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0377 - custom_f1: 0.8034 - val_loss: 0.0355 - val_custom_f1: 0.8312\n",
      "Epoch 436/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8339 - val_loss: 0.0358 - val_custom_f1: 0.8387\n",
      "Epoch 437/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8336 - val_loss: 0.0383 - val_custom_f1: 0.8333\n",
      "Epoch 438/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8064 - val_loss: 0.0354 - val_custom_f1: 0.8481\n",
      "Epoch 439/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8210 - val_loss: 0.0350 - val_custom_f1: 0.8481\n",
      "Epoch 440/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.7783 - val_loss: 0.0371 - val_custom_f1: 0.8333\n",
      "Epoch 441/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0373 - custom_f1: 0.8090 - val_loss: 0.0368 - val_custom_f1: 0.8387\n",
      "Epoch 442/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8247 - val_loss: 0.0347 - val_custom_f1: 0.8462\n",
      "Epoch 443/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8298 - val_loss: 0.0347 - val_custom_f1: 0.8553\n",
      "Epoch 444/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8303 - val_loss: 0.0355 - val_custom_f1: 0.8408\n",
      "Epoch 445/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0364 - custom_f1: 0.7900 - val_loss: 0.0361 - val_custom_f1: 0.8387\n",
      "Epoch 446/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0348 - custom_f1: 0.8091 - val_loss: 0.0352 - val_custom_f1: 0.8408\n",
      "Epoch 447/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0339 - custom_f1: 0.8322 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 448/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8231 - val_loss: 0.0344 - val_custom_f1: 0.8553\n",
      "Epoch 449/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0342 - custom_f1: 0.8318 - val_loss: 0.0355 - val_custom_f1: 0.8333\n",
      "Epoch 450/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8151 - val_loss: 0.0352 - val_custom_f1: 0.8408\n",
      "Epoch 451/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8051 - val_loss: 0.0345 - val_custom_f1: 0.8625\n",
      "Epoch 452/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.8169 - val_loss: 0.0344 - val_custom_f1: 0.8696\n",
      "Epoch 453/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.7850 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 454/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0376 - custom_f1: 0.8029 - val_loss: 0.0342 - val_custom_f1: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - custom_f1: 0.8288 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 456/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8451 - val_loss: 0.0344 - val_custom_f1: 0.8481\n",
      "Epoch 457/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.7878 - val_loss: 0.0351 - val_custom_f1: 0.8258\n",
      "Epoch 458/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.7894 - val_loss: 0.0347 - val_custom_f1: 0.8333\n",
      "Epoch 459/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.8077 - val_loss: 0.0346 - val_custom_f1: 0.8481\n",
      "Epoch 460/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8215 - val_loss: 0.0350 - val_custom_f1: 0.8481\n",
      "Epoch 461/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - custom_f1: 0.8628 - val_loss: 0.0357 - val_custom_f1: 0.8553\n",
      "Epoch 462/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0354 - custom_f1: 0.8337 - val_loss: 0.0355 - val_custom_f1: 0.8333\n",
      "Epoch 463/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8336 - val_loss: 0.0358 - val_custom_f1: 0.8333\n",
      "Epoch 464/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0363 - custom_f1: 0.8112 - val_loss: 0.0368 - val_custom_f1: 0.8333\n",
      "Epoch 465/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0345 - custom_f1: 0.8244 - val_loss: 0.0371 - val_custom_f1: 0.8333\n",
      "Epoch 466/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0354 - custom_f1: 0.8327 - val_loss: 0.0359 - val_custom_f1: 0.8333\n",
      "Epoch 467/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8154 - val_loss: 0.0348 - val_custom_f1: 0.8333\n",
      "Epoch 468/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8309 - val_loss: 0.0355 - val_custom_f1: 0.8333\n",
      "Epoch 469/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8245 - val_loss: 0.0344 - val_custom_f1: 0.8408\n",
      "Epoch 470/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - custom_f1: 0.8162 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 471/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - custom_f1: 0.8524 - val_loss: 0.0354 - val_custom_f1: 0.8481\n",
      "Epoch 472/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8225 - val_loss: 0.0351 - val_custom_f1: 0.8553\n",
      "Epoch 473/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8192 - val_loss: 0.0339 - val_custom_f1: 0.8625\n",
      "Epoch 474/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8040 - val_loss: 0.0340 - val_custom_f1: 0.8625\n",
      "Epoch 475/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8123 - val_loss: 0.0348 - val_custom_f1: 0.8625\n",
      "Epoch 476/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0363 - custom_f1: 0.8310 - val_loss: 0.0349 - val_custom_f1: 0.8625\n",
      "Epoch 477/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0349 - custom_f1: 0.8047 - val_loss: 0.0349 - val_custom_f1: 0.8333\n",
      "Epoch 478/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - custom_f1: 0.8308 - val_loss: 0.0350 - val_custom_f1: 0.8258\n",
      "Epoch 479/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.8124 - val_loss: 0.0346 - val_custom_f1: 0.8258\n",
      "Epoch 480/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0354 - custom_f1: 0.8095 - val_loss: 0.0332 - val_custom_f1: 0.8258\n",
      "Epoch 481/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.8185 - val_loss: 0.0345 - val_custom_f1: 0.8312\n",
      "Epoch 482/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.8174 - val_loss: 0.0336 - val_custom_f1: 0.8258\n",
      "Epoch 483/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8263 - val_loss: 0.0318 - val_custom_f1: 0.8696\n",
      "Epoch 484/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8203 - val_loss: 0.0320 - val_custom_f1: 0.8696\n",
      "Epoch 485/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8258 - val_loss: 0.0329 - val_custom_f1: 0.8696\n",
      "Epoch 486/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8266 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 487/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0381 - custom_f1: 0.8211 - val_loss: 0.0333 - val_custom_f1: 0.8696\n",
      "Epoch 488/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0345 - custom_f1: 0.8212 - val_loss: 0.0332 - val_custom_f1: 0.8696\n",
      "Epoch 489/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.8350 - val_loss: 0.0333 - val_custom_f1: 0.8462\n",
      "Epoch 490/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0330 - custom_f1: 0.8309 - val_loss: 0.0345 - val_custom_f1: 0.8312\n",
      "Epoch 491/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0344 - custom_f1: 0.8222 - val_loss: 0.0339 - val_custom_f1: 0.8333\n",
      "Epoch 492/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8320 - val_loss: 0.0335 - val_custom_f1: 0.8553\n",
      "Epoch 493/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8091 - val_loss: 0.0343 - val_custom_f1: 0.8553\n",
      "Epoch 494/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - custom_f1: 0.8092 - val_loss: 0.0343 - val_custom_f1: 0.8333\n",
      "Epoch 495/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8114 - val_loss: 0.0339 - val_custom_f1: 0.8481\n",
      "Epoch 496/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - custom_f1: 0.8176 - val_loss: 0.0346 - val_custom_f1: 0.8481\n",
      "Epoch 497/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8134 - val_loss: 0.0341 - val_custom_f1: 0.8235\n",
      "Epoch 498/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0374 - custom_f1: 0.7979 - val_loss: 0.0343 - val_custom_f1: 0.8235\n",
      "Epoch 499/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8374 - val_loss: 0.0344 - val_custom_f1: 0.8333\n",
      "Epoch 500/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0377 - custom_f1: 0.8472 - val_loss: 0.0349 - val_custom_f1: 0.8481\n",
      "Epoch 501/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8244 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 502/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - custom_f1: 0.8384 - val_loss: 0.0332 - val_custom_f1: 0.8481\n",
      "Epoch 503/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8449 - val_loss: 0.0344 - val_custom_f1: 0.8333\n",
      "Epoch 504/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.7996 - val_loss: 0.0329 - val_custom_f1: 0.8481\n",
      "Epoch 505/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8374 - val_loss: 0.0329 - val_custom_f1: 0.8312\n",
      "Epoch 506/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.7832 - val_loss: 0.0328 - val_custom_f1: 0.8481\n",
      "Epoch 507/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0351 - custom_f1: 0.7970 - val_loss: 0.0320 - val_custom_f1: 0.8696\n",
      "Epoch 508/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0349 - custom_f1: 0.8167 - val_loss: 0.0321 - val_custom_f1: 0.8696\n",
      "Epoch 509/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8080 - val_loss: 0.0325 - val_custom_f1: 0.8696\n",
      "Epoch 510/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8371 - val_loss: 0.0331 - val_custom_f1: 0.8696\n",
      "Epoch 511/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0339 - custom_f1: 0.8272 - val_loss: 0.0333 - val_custom_f1: 0.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8250 - val_loss: 0.0330 - val_custom_f1: 0.8696\n",
      "Epoch 513/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8246 - val_loss: 0.0338 - val_custom_f1: 0.8696\n",
      "Epoch 514/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.7981 - val_loss: 0.0343 - val_custom_f1: 0.8553\n",
      "Epoch 515/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0353 - custom_f1: 0.8194 - val_loss: 0.0357 - val_custom_f1: 0.8553\n",
      "Epoch 516/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.8149 - val_loss: 0.0349 - val_custom_f1: 0.8553\n",
      "Epoch 517/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8195 - val_loss: 0.0346 - val_custom_f1: 0.8696\n",
      "Epoch 518/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.7797 - val_loss: 0.0343 - val_custom_f1: 0.8696\n",
      "Epoch 519/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0354 - custom_f1: 0.7780 - val_loss: 0.0345 - val_custom_f1: 0.8696\n",
      "Epoch 520/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - custom_f1: 0.7984 - val_loss: 0.0346 - val_custom_f1: 0.8625\n",
      "Epoch 521/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8254 - val_loss: 0.0333 - val_custom_f1: 0.8696\n",
      "Epoch 522/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - custom_f1: 0.8379 - val_loss: 0.0355 - val_custom_f1: 0.8553\n",
      "Epoch 523/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8356 - val_loss: 0.0337 - val_custom_f1: 0.8333\n",
      "Epoch 524/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.8258 - val_loss: 0.0342 - val_custom_f1: 0.8235\n",
      "Epoch 525/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - custom_f1: 0.8383 - val_loss: 0.0362 - val_custom_f1: 0.8387\n",
      "Epoch 526/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0380 - custom_f1: 0.8193 - val_loss: 0.0334 - val_custom_f1: 0.8696\n",
      "Epoch 527/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0382 - custom_f1: 0.8030 - val_loss: 0.0328 - val_custom_f1: 0.8696\n",
      "Epoch 528/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0375 - custom_f1: 0.7927 - val_loss: 0.0337 - val_custom_f1: 0.8696\n",
      "Epoch 529/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0364 - custom_f1: 0.8292 - val_loss: 0.0340 - val_custom_f1: 0.8696\n",
      "Epoch 530/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8295 - val_loss: 0.0331 - val_custom_f1: 0.8696\n",
      "Epoch 531/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8232 - val_loss: 0.0329 - val_custom_f1: 0.8696\n",
      "Epoch 532/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0363 - custom_f1: 0.8138 - val_loss: 0.0338 - val_custom_f1: 0.8625\n",
      "Epoch 533/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8257 - val_loss: 0.0339 - val_custom_f1: 0.8535\n",
      "Epoch 534/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.7920 - val_loss: 0.0340 - val_custom_f1: 0.8387\n",
      "Epoch 535/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8281 - val_loss: 0.0346 - val_custom_f1: 0.8553\n",
      "Epoch 536/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0345 - custom_f1: 0.8410 - val_loss: 0.0348 - val_custom_f1: 0.8696\n",
      "Epoch 537/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0392 - custom_f1: 0.8380 - val_loss: 0.0337 - val_custom_f1: 0.8625\n",
      "Epoch 538/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0354 - custom_f1: 0.8479 - val_loss: 0.0343 - val_custom_f1: 0.8553\n",
      "Epoch 539/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8457 - val_loss: 0.0351 - val_custom_f1: 0.8553\n",
      "Epoch 540/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0333 - custom_f1: 0.8323 - val_loss: 0.0352 - val_custom_f1: 0.8625\n",
      "Epoch 541/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.7895 - val_loss: 0.0352 - val_custom_f1: 0.8696\n",
      "Epoch 542/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0353 - custom_f1: 0.8175 - val_loss: 0.0352 - val_custom_f1: 0.8625\n",
      "Epoch 543/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.8310 - val_loss: 0.0371 - val_custom_f1: 0.8625\n",
      "Epoch 544/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0391 - custom_f1: 0.8410 - val_loss: 0.0356 - val_custom_f1: 0.8625\n",
      "Epoch 545/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8208 - val_loss: 0.0342 - val_custom_f1: 0.8696\n",
      "Epoch 546/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8276 - val_loss: 0.0334 - val_custom_f1: 0.8625\n",
      "Epoch 547/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8063 - val_loss: 0.0344 - val_custom_f1: 0.8625\n",
      "Epoch 548/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0376 - custom_f1: 0.8419 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 549/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8100 - val_loss: 0.0332 - val_custom_f1: 0.8642\n",
      "Epoch 550/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0386 - custom_f1: 0.8131 - val_loss: 0.0345 - val_custom_f1: 0.8589\n",
      "Epoch 551/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8391 - val_loss: 0.0353 - val_custom_f1: 0.8642\n",
      "Epoch 552/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0381 - custom_f1: 0.8066 - val_loss: 0.0347 - val_custom_f1: 0.8642\n",
      "Epoch 553/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8083 - val_loss: 0.0338 - val_custom_f1: 0.8571\n",
      "Epoch 554/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0389 - custom_f1: 0.7709 - val_loss: 0.0332 - val_custom_f1: 0.8642\n",
      "Epoch 555/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0387 - custom_f1: 0.8157 - val_loss: 0.0329 - val_custom_f1: 0.8642\n",
      "Epoch 556/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0376 - custom_f1: 0.8330 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 557/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0374 - custom_f1: 0.8501 - val_loss: 0.0350 - val_custom_f1: 0.8625\n",
      "Epoch 558/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - custom_f1: 0.8328 - val_loss: 0.0334 - val_custom_f1: 0.8625\n",
      "Epoch 559/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0376 - custom_f1: 0.8321 - val_loss: 0.0330 - val_custom_f1: 0.8625\n",
      "Epoch 560/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.8273 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 561/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8132 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 562/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0379 - custom_f1: 0.8184 - val_loss: 0.0323 - val_custom_f1: 0.8696\n",
      "Epoch 563/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - custom_f1: 0.8257 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 564/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0368 - custom_f1: 0.8301 - val_loss: 0.0333 - val_custom_f1: 0.8625\n",
      "Epoch 565/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0366 - custom_f1: 0.8290 - val_loss: 0.0325 - val_custom_f1: 0.8553\n",
      "Epoch 566/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8332 - val_loss: 0.0344 - val_custom_f1: 0.8553\n",
      "Epoch 567/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0373 - custom_f1: 0.7973 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 568/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.8068 - val_loss: 0.0338 - val_custom_f1: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8320 - val_loss: 0.0352 - val_custom_f1: 0.8642\n",
      "Epoch 570/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0396 - custom_f1: 0.8285 - val_loss: 0.0355 - val_custom_f1: 0.8696\n",
      "Epoch 571/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0382 - custom_f1: 0.8378 - val_loss: 0.0332 - val_custom_f1: 0.8696\n",
      "Epoch 572/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8027 - val_loss: 0.0323 - val_custom_f1: 0.8696\n",
      "Epoch 573/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8198 - val_loss: 0.0325 - val_custom_f1: 0.8696\n",
      "Epoch 574/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8236 - val_loss: 0.0334 - val_custom_f1: 0.8625\n",
      "Epoch 575/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8146 - val_loss: 0.0344 - val_custom_f1: 0.8535\n",
      "Epoch 576/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0379 - custom_f1: 0.7993 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 577/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0380 - custom_f1: 0.8120 - val_loss: 0.0334 - val_custom_f1: 0.8625\n",
      "Epoch 578/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8322 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 579/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0395 - custom_f1: 0.8257 - val_loss: 0.0346 - val_custom_f1: 0.8408\n",
      "Epoch 580/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0356 - custom_f1: 0.8293 - val_loss: 0.0354 - val_custom_f1: 0.8387\n",
      "Epoch 581/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8208 - val_loss: 0.0356 - val_custom_f1: 0.8387\n",
      "Epoch 582/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8224 - val_loss: 0.0363 - val_custom_f1: 0.8387\n",
      "Epoch 583/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8138 - val_loss: 0.0346 - val_custom_f1: 0.8535\n",
      "Epoch 584/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8312 - val_loss: 0.0348 - val_custom_f1: 0.8535\n",
      "Epoch 585/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0356 - custom_f1: 0.8074 - val_loss: 0.0378 - val_custom_f1: 0.8481\n",
      "Epoch 586/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8228 - val_loss: 0.0349 - val_custom_f1: 0.8553\n",
      "Epoch 587/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8096 - val_loss: 0.0332 - val_custom_f1: 0.8625\n",
      "Epoch 588/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8293 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 589/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0383 - custom_f1: 0.7986 - val_loss: 0.0345 - val_custom_f1: 0.8679\n",
      "Epoch 590/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8400 - val_loss: 0.0354 - val_custom_f1: 0.8535\n",
      "Epoch 591/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8131 - val_loss: 0.0379 - val_custom_f1: 0.8535\n",
      "Epoch 592/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.8103 - val_loss: 0.0343 - val_custom_f1: 0.8679\n",
      "Epoch 593/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - custom_f1: 0.8338 - val_loss: 0.0331 - val_custom_f1: 0.8679\n",
      "Epoch 594/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0368 - custom_f1: 0.8106 - val_loss: 0.0357 - val_custom_f1: 0.8535\n",
      "Epoch 595/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8007 - val_loss: 0.0351 - val_custom_f1: 0.8535\n",
      "Epoch 596/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0392 - custom_f1: 0.7869 - val_loss: 0.0329 - val_custom_f1: 0.8625\n",
      "Epoch 597/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8263 - val_loss: 0.0339 - val_custom_f1: 0.8696\n",
      "Epoch 598/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0384 - custom_f1: 0.8117 - val_loss: 0.0345 - val_custom_f1: 0.8625\n",
      "Epoch 599/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0357 - custom_f1: 0.8229 - val_loss: 0.0339 - val_custom_f1: 0.8625\n",
      "Epoch 600/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8249 - val_loss: 0.0338 - val_custom_f1: 0.8696\n",
      "Epoch 601/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8042 - val_loss: 0.0349 - val_custom_f1: 0.8696\n",
      "Epoch 602/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8285 - val_loss: 0.0340 - val_custom_f1: 0.8696\n",
      "Epoch 603/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0351 - custom_f1: 0.8258 - val_loss: 0.0343 - val_custom_f1: 0.8696\n",
      "Epoch 604/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0371 - custom_f1: 0.8114 - val_loss: 0.0350 - val_custom_f1: 0.8696\n",
      "Epoch 605/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0355 - custom_f1: 0.8297 - val_loss: 0.0359 - val_custom_f1: 0.8481\n",
      "Epoch 606/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0341 - custom_f1: 0.8348 - val_loss: 0.0358 - val_custom_f1: 0.8481\n",
      "Epoch 607/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0350 - custom_f1: 0.8464 - val_loss: 0.0344 - val_custom_f1: 0.8481\n",
      "Epoch 608/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.7913 - val_loss: 0.0342 - val_custom_f1: 0.8553\n",
      "Epoch 609/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8053 - val_loss: 0.0347 - val_custom_f1: 0.8625\n",
      "Epoch 610/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8044 - val_loss: 0.0345 - val_custom_f1: 0.8696\n",
      "Epoch 611/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8092 - val_loss: 0.0354 - val_custom_f1: 0.8696\n",
      "Epoch 612/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0340 - custom_f1: 0.8276 - val_loss: 0.0343 - val_custom_f1: 0.8642\n",
      "Epoch 613/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.8066 - val_loss: 0.0346 - val_custom_f1: 0.8625\n",
      "Epoch 614/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8054 - val_loss: 0.0358 - val_custom_f1: 0.8408\n",
      "Epoch 615/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0376 - custom_f1: 0.7888 - val_loss: 0.0351 - val_custom_f1: 0.8182\n",
      "Epoch 616/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.8268 - val_loss: 0.0338 - val_custom_f1: 0.8481\n",
      "Epoch 617/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0391 - custom_f1: 0.8072 - val_loss: 0.0338 - val_custom_f1: 0.8408\n",
      "Epoch 618/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.7816 - val_loss: 0.0361 - val_custom_f1: 0.8182\n",
      "Epoch 619/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0399 - custom_f1: 0.7824 - val_loss: 0.0350 - val_custom_f1: 0.8408\n",
      "Epoch 620/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0382 - custom_f1: 0.8227 - val_loss: 0.0347 - val_custom_f1: 0.8481\n",
      "Epoch 621/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0381 - custom_f1: 0.8033 - val_loss: 0.0336 - val_custom_f1: 0.8553\n",
      "Epoch 622/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0372 - custom_f1: 0.7998 - val_loss: 0.0335 - val_custom_f1: 0.8696\n",
      "Epoch 623/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8012 - val_loss: 0.0347 - val_custom_f1: 0.8625\n",
      "Epoch 624/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8089 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 625/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.8058 - val_loss: 0.0343 - val_custom_f1: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8144 - val_loss: 0.0343 - val_custom_f1: 0.8481\n",
      "Epoch 627/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0381 - custom_f1: 0.8100 - val_loss: 0.0348 - val_custom_f1: 0.8481\n",
      "Epoch 628/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8172 - val_loss: 0.0371 - val_custom_f1: 0.8333\n",
      "Epoch 629/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0380 - custom_f1: 0.8291 - val_loss: 0.0361 - val_custom_f1: 0.8258\n",
      "Epoch 630/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8444 - val_loss: 0.0363 - val_custom_f1: 0.8258\n",
      "Epoch 631/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - custom_f1: 0.8298 - val_loss: 0.0379 - val_custom_f1: 0.8182\n",
      "Epoch 632/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8273 - val_loss: 0.0370 - val_custom_f1: 0.8333\n",
      "Epoch 633/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0355 - custom_f1: 0.7839 - val_loss: 0.0359 - val_custom_f1: 0.8408\n",
      "Epoch 634/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0383 - custom_f1: 0.8054 - val_loss: 0.0359 - val_custom_f1: 0.8408\n",
      "Epoch 635/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0396 - custom_f1: 0.7932 - val_loss: 0.0348 - val_custom_f1: 0.8462\n",
      "Epoch 636/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0368 - custom_f1: 0.7747 - val_loss: 0.0333 - val_custom_f1: 0.8590\n",
      "Epoch 637/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8330 - val_loss: 0.0332 - val_custom_f1: 0.8590\n",
      "Epoch 638/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0391 - custom_f1: 0.8124 - val_loss: 0.0332 - val_custom_f1: 0.8481\n",
      "Epoch 639/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0391 - custom_f1: 0.7857 - val_loss: 0.0341 - val_custom_f1: 0.8481\n",
      "Epoch 640/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.8065 - val_loss: 0.0337 - val_custom_f1: 0.8625\n",
      "Epoch 641/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - custom_f1: 0.8068 - val_loss: 0.0355 - val_custom_f1: 0.8571\n",
      "Epoch 642/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0374 - custom_f1: 0.8261 - val_loss: 0.0346 - val_custom_f1: 0.8571\n",
      "Epoch 643/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0369 - custom_f1: 0.7709 - val_loss: 0.0346 - val_custom_f1: 0.8571\n",
      "Epoch 644/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.7876 - val_loss: 0.0344 - val_custom_f1: 0.8571\n",
      "Epoch 645/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - custom_f1: 0.8084 - val_loss: 0.0345 - val_custom_f1: 0.8434\n",
      "Epoch 646/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0389 - custom_f1: 0.8175 - val_loss: 0.0340 - val_custom_f1: 0.8642\n",
      "Epoch 647/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - custom_f1: 0.8159 - val_loss: 0.0349 - val_custom_f1: 0.8481\n",
      "Epoch 648/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0391 - custom_f1: 0.8158 - val_loss: 0.0347 - val_custom_f1: 0.8481\n",
      "Epoch 649/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0383 - custom_f1: 0.8010 - val_loss: 0.0339 - val_custom_f1: 0.8625\n",
      "Epoch 650/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0392 - custom_f1: 0.7837 - val_loss: 0.0337 - val_custom_f1: 0.8481\n",
      "Epoch 651/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8224 - val_loss: 0.0345 - val_custom_f1: 0.8481\n",
      "Epoch 652/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0368 - custom_f1: 0.8275 - val_loss: 0.0348 - val_custom_f1: 0.8481\n",
      "Epoch 653/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0358 - custom_f1: 0.8262 - val_loss: 0.0337 - val_custom_f1: 0.8481\n",
      "Epoch 654/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8029 - val_loss: 0.0341 - val_custom_f1: 0.8481\n",
      "Epoch 655/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8026 - val_loss: 0.0345 - val_custom_f1: 0.8481\n",
      "Epoch 656/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8072 - val_loss: 0.0349 - val_custom_f1: 0.8481\n",
      "Epoch 657/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0380 - custom_f1: 0.7619 - val_loss: 0.0350 - val_custom_f1: 0.8481\n",
      "Epoch 658/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0393 - custom_f1: 0.7967 - val_loss: 0.0347 - val_custom_f1: 0.8625\n",
      "Epoch 659/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.8253 - val_loss: 0.0347 - val_custom_f1: 0.8553\n",
      "Epoch 660/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0380 - custom_f1: 0.8132 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 661/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - custom_f1: 0.8023 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 662/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.8083 - val_loss: 0.0350 - val_custom_f1: 0.8625\n",
      "Epoch 663/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0365 - custom_f1: 0.7981 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 664/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0394 - custom_f1: 0.8014 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 665/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8040 - val_loss: 0.0363 - val_custom_f1: 0.8625\n",
      "Epoch 666/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0385 - custom_f1: 0.8157 - val_loss: 0.0335 - val_custom_f1: 0.8625\n",
      "Epoch 667/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8208 - val_loss: 0.0336 - val_custom_f1: 0.8625\n",
      "Epoch 668/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.8153 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 669/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - custom_f1: 0.8207 - val_loss: 0.0342 - val_custom_f1: 0.8625\n",
      "Epoch 670/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - custom_f1: 0.8068 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 671/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8218 - val_loss: 0.0343 - val_custom_f1: 0.8625\n",
      "Epoch 672/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0377 - custom_f1: 0.8129 - val_loss: 0.0340 - val_custom_f1: 0.8625\n",
      "Epoch 673/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0359 - custom_f1: 0.7942 - val_loss: 0.0339 - val_custom_f1: 0.8625\n",
      "Epoch 674/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0361 - custom_f1: 0.8042 - val_loss: 0.0338 - val_custom_f1: 0.8642\n",
      "Epoch 675/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8221 - val_loss: 0.0348 - val_custom_f1: 0.8642\n",
      "Epoch 676/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0362 - custom_f1: 0.8118 - val_loss: 0.0341 - val_custom_f1: 0.8625\n",
      "Epoch 677/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - custom_f1: 0.8090 - val_loss: 0.0342 - val_custom_f1: 0.8625\n",
      "Epoch 678/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0366 - custom_f1: 0.8168 - val_loss: 0.0360 - val_custom_f1: 0.8625\n",
      "Epoch 679/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8093 - val_loss: 0.0356 - val_custom_f1: 0.8481\n",
      "Epoch 680/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - custom_f1: 0.8051 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 681/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0375 - custom_f1: 0.8074 - val_loss: 0.0347 - val_custom_f1: 0.8481\n",
      "Epoch 682/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0372 - custom_f1: 0.8200 - val_loss: 0.0351 - val_custom_f1: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0362 - custom_f1: 0.8112 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 684/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0352 - custom_f1: 0.8273 - val_loss: 0.0363 - val_custom_f1: 0.8481\n",
      "Epoch 685/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0357 - custom_f1: 0.8314 - val_loss: 0.0358 - val_custom_f1: 0.8553\n",
      "Epoch 686/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0362 - custom_f1: 0.8212 - val_loss: 0.0350 - val_custom_f1: 0.8765\n",
      "Epoch 687/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0380 - custom_f1: 0.7884 - val_loss: 0.0358 - val_custom_f1: 0.8481\n",
      "Epoch 688/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0360 - custom_f1: 0.8342 - val_loss: 0.0387 - val_custom_f1: 0.8462\n",
      "Epoch 689/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8432 - val_loss: 0.0373 - val_custom_f1: 0.8481\n",
      "Epoch 690/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0362 - custom_f1: 0.8271 - val_loss: 0.0346 - val_custom_f1: 0.8553\n",
      "Epoch 691/725\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0386 - custom_f1: 0.7994 - val_loss: 0.0341 - val_custom_f1: 0.8481\n",
      "Epoch 692/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - custom_f1: 0.8244 - val_loss: 0.0353 - val_custom_f1: 0.8553\n",
      "Epoch 693/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0338 - custom_f1: 0.8437 - val_loss: 0.0376 - val_custom_f1: 0.8625\n",
      "Epoch 694/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0385 - custom_f1: 0.8325 - val_loss: 0.0349 - val_custom_f1: 0.8625\n",
      "Epoch 695/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0359 - custom_f1: 0.8299 - val_loss: 0.0348 - val_custom_f1: 0.8625\n",
      "Epoch 696/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - custom_f1: 0.7972 - val_loss: 0.0366 - val_custom_f1: 0.8481\n",
      "Epoch 697/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0354 - custom_f1: 0.8161 - val_loss: 0.0382 - val_custom_f1: 0.8333\n",
      "Epoch 698/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0363 - custom_f1: 0.8271 - val_loss: 0.0365 - val_custom_f1: 0.8333\n",
      "Epoch 699/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0347 - custom_f1: 0.8196 - val_loss: 0.0367 - val_custom_f1: 0.8408\n",
      "Epoch 700/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0348 - custom_f1: 0.8212 - val_loss: 0.0368 - val_custom_f1: 0.8408\n",
      "Epoch 701/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0380 - custom_f1: 0.7953 - val_loss: 0.0355 - val_custom_f1: 0.8408\n",
      "Epoch 702/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0370 - custom_f1: 0.8180 - val_loss: 0.0362 - val_custom_f1: 0.8408\n",
      "Epoch 703/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0360 - custom_f1: 0.8134 - val_loss: 0.0356 - val_custom_f1: 0.8625\n",
      "Epoch 704/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0357 - custom_f1: 0.8001 - val_loss: 0.0346 - val_custom_f1: 0.8625\n",
      "Epoch 705/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0394 - custom_f1: 0.7809 - val_loss: 0.0346 - val_custom_f1: 0.8519\n",
      "Epoch 706/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0367 - custom_f1: 0.7987 - val_loss: 0.0351 - val_custom_f1: 0.8625\n",
      "Epoch 707/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0387 - custom_f1: 0.8260 - val_loss: 0.0360 - val_custom_f1: 0.8625\n",
      "Epoch 708/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0394 - custom_f1: 0.7976 - val_loss: 0.0352 - val_custom_f1: 0.8625\n",
      "Epoch 709/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0385 - custom_f1: 0.8200 - val_loss: 0.0349 - val_custom_f1: 0.8625\n",
      "Epoch 710/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0369 - custom_f1: 0.8226 - val_loss: 0.0354 - val_custom_f1: 0.8625\n",
      "Epoch 711/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0370 - custom_f1: 0.8034 - val_loss: 0.0355 - val_custom_f1: 0.8625\n",
      "Epoch 712/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0387 - custom_f1: 0.7893 - val_loss: 0.0359 - val_custom_f1: 0.8553\n",
      "Epoch 713/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0394 - custom_f1: 0.7959 - val_loss: 0.0364 - val_custom_f1: 0.8625\n",
      "Epoch 714/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0378 - custom_f1: 0.8410 - val_loss: 0.0370 - val_custom_f1: 0.8625\n",
      "Epoch 715/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8010 - val_loss: 0.0353 - val_custom_f1: 0.8481\n",
      "Epoch 716/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0388 - custom_f1: 0.7972 - val_loss: 0.0359 - val_custom_f1: 0.8481\n",
      "Epoch 717/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0382 - custom_f1: 0.8453 - val_loss: 0.0369 - val_custom_f1: 0.8428\n",
      "Epoch 718/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0399 - custom_f1: 0.8069 - val_loss: 0.0389 - val_custom_f1: 0.8408\n",
      "Epoch 719/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0393 - custom_f1: 0.8315 - val_loss: 0.0356 - val_custom_f1: 0.8481\n",
      "Epoch 720/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - custom_f1: 0.7904 - val_loss: 0.0349 - val_custom_f1: 0.8625\n",
      "Epoch 721/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0368 - custom_f1: 0.8326 - val_loss: 0.0349 - val_custom_f1: 0.8625\n",
      "Epoch 722/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0373 - custom_f1: 0.8416 - val_loss: 0.0362 - val_custom_f1: 0.8625\n",
      "Epoch 723/725\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0382 - custom_f1: 0.8287 - val_loss: 0.0366 - val_custom_f1: 0.8625\n",
      "Epoch 724/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0391 - custom_f1: 0.8021 - val_loss: 0.0354 - val_custom_f1: 0.8625\n",
      "Epoch 725/725\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0379 - custom_f1: 0.8328 - val_loss: 0.0354 - val_custom_f1: 0.8481\n"
     ]
    }
   ],
   "source": [
    "#The reason I love this tuner is because it gets of overfitting 'val loss almost equal to loss'\n",
    "#F1 score is not the best, but this was expected, the source data is already PCA transformed and tough to work with\n",
    "#We can further improve this by using feature selection, and changing the amount of data that we trained this model on\n",
    "#F1 score of over 90 should be achievable without overfitting\n",
    "\n",
    "model = final_model(30, 0.0563)\n",
    "x_train,y_train = split_scale_data(ccdb.iloc[:,:-1],ccdb.iloc[:,-1])\n",
    "history = model.fit(x_train,y_train,batch_size=5326,validation_split=0.2,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97ebddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03555995225906372, 0.868494987487793]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate loss and F1 on test data\n",
    "x_test,y_test = split_scale_data(ccdb.iloc[:,:-1],ccdb.iloc[:,-1], phase='test')\n",
    "model.test_on_batch(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5591da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize loss on train and validation datasets\n",
    "\n",
    "plt.plot(history.history['loss'][5:750])\n",
    "plt.plot(history.history['val_loss'][5:750])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
